{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8G5SRDsAnAF",
        "outputId": "564099f8-f330-4e70-a84e-984387a45084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --q datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "VXkFakVUAtkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/bigcode-project/bigcode-dataset\n",
        "%cd /content/bigcode-dataset/near_deduplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOP16GN2DRZv",
        "outputId": "ec48652d-82d0-42ba-844a-d7abc753a120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'bigcode-dataset'...\n",
            "remote: Enumerating objects: 789, done.\u001b[K\n",
            "remote: Counting objects: 100% (278/278), done.\u001b[K\n",
            "remote: Compressing objects: 100% (155/155), done.\u001b[K\n",
            "remote: Total 789 (delta 155), reused 212 (delta 123), pack-reused 511\u001b[K\n",
            "Receiving objects: 100% (789/789), 3.04 MiB | 22.53 MiB/s, done.\n",
            "Resolving deltas: 100% (458/458), done.\n",
            "/content/bigcode-dataset/near_deduplication\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --q -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIi1RyyaDb95",
        "outputId": "b46b1f4e-7d0e-4b45-d7d9-c11ba9d771dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, concatenate_datasets, Dataset, DatasetDict, load_from_disk"
      ],
      "metadata": {
        "id": "1OLv9Kd5Avp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_text(sample):\n",
        "  return {\n",
        "      \"text\": sample[\"bot_name\"] + \"\\n\" + sample[\"personalities\"] + \"\\n\" + sample[\"categories\"]\n",
        "  }\n",
        "\n",
        "def prepare_dataset(dataset_path):\n",
        "  ds = load_dataset(dataset_path)\n",
        "  joined_ds = concatenate_datasets(ds.values())\n",
        "  samples = joined_ds.to_list()\n",
        "  deduplicated_samples = list({v['bot_name']: v for v in samples}.values())\n",
        "  deduplicated_dataset = Dataset.from_list(deduplicated_samples)\n",
        "  deduplicated_dataset = deduplicated_dataset.map(add_text)\n",
        "  name_deduped_path = dataset_path + \"-name-deduped\"\n",
        "  deduplicated_dataset.push_to_hub(name_deduped_path, private=True)\n",
        "  !python minhash_deduplication.py --dataset $name_deduped_path \\\n",
        "    --split train \\\n",
        "    --column text \\\n",
        "    --cache-dir .cache \\\n",
        "    --min-ngram-size 1 \\\n",
        "    --ngram-size 1 \\\n",
        "    --threshold 0.65\n",
        "  deduplicated_dataset = load_from_disk(\"output/deduplicated\")\n",
        "  deduplicated_dataset = deduplicated_dataset.remove_columns(\"text\")\n",
        "  deduplicated_dataset.push_to_hub(dataset_path + \"-prepared\")\n",
        "  print(deduplicated_dataset)\n",
        "  return deduplicated_dataset"
      ],
      "metadata": {
        "id": "gGleKl3BEY2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_dataset = prepare_dataset(\"AlekseyKorshuk/character-profiles-romance\")"
      ],
      "metadata": {
        "id": "jgyO1jbeEsPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_dataset = prepare_dataset(\"AlekseyKorshuk/character-profiles-friendly\")"
      ],
      "metadata": {
        "id": "u6qIwFkME4uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_dataset = prepare_dataset(\"AlekseyKorshuk/character-profiles-fight\")"
      ],
      "metadata": {
        "id": "yH9elrMHE7J4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}